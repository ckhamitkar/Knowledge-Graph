{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia as wp \n",
    "import re\n",
    "import requests\n",
    "import spacy\n",
    "import spacy_transformers\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher\n",
    "import networkx as nx\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the language of the response\n",
    "wp.set_lang(\"en\")\n",
    "\n",
    "# Obtain and store the data\n",
    "title = \" 'Boston, Massachusetts' \"\n",
    "data = wp.page(title).content\n",
    "\n",
    "# View the data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to lowercase and replace new lines\n",
    "data = data.lower().replace('\\n', \"\")\n",
    "\n",
    "# Remove the last part of the text, certain punctuation marks, headings, as well as any text within the parentheses\n",
    "data = re.sub('== see also ==.*|[@#:&\\\"]|===.*?===|==.*?==|\\(.*?\\)', '', data)\n",
    "\n",
    "# View the data\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a language model\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "doc=nlp(data)\n",
    "\n",
    "# Display the entities in the doc\n",
    "displacy.render(doc,style=\"ent\",jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the coreference resolution component in the pipeline\n",
    "nlp.add_pipe('coreferee')\n",
    "\n",
    "# Pass the data to the language model \n",
    "doc = nlp(data)\n",
    "\n",
    "# Print resolved coreferences, if any\n",
    "doc._.coref_chains.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_data = \"\"\n",
    "for token in doc:\n",
    "    resolved_coref = doc._.coref_chains.resolve(token)\n",
    "    if resolved_coref:\n",
    "        resolved_data += \" \" + \" and \".join(r.text for r in resolved_coref)\n",
    "    elif token.dep_ == \"punct\":\n",
    "        resolved_data += token.text\n",
    "    else:\n",
    "        resolved_data += \" \" + token.text\n",
    "print(resolved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_relationship(sentence):\n",
    "    doc = nlp(sentence)\n",
    "    \n",
    "    first, last = None, None\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        if not first:\n",
    "            first = chunk\n",
    "        else:\n",
    "            last = chunk\n",
    "\n",
    "    if first and last:\n",
    "        return (first.text.strip(), last.text.strip(), str(doc[first.end:last.start]).strip())\n",
    "    \n",
    "    return (None, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#A helper function that prints 5 words per row. Can be used for better readability of a given text.\n",
    "print_five_words = lambda sentence: '\\n'.join(' '.join(sentence.split()[i:i+5]) for i in range(0, len(sentence.split()), 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Network object\n",
    "graph_doc = nlp(resolved_data)\n",
    "\n",
    "# Create an empty graph\n",
    "nx_graph = nx.DiGraph()\n",
    "\n",
    "for sent in enumerate(graph_doc.sents) :\n",
    "    if len(sent[1]) > 3:\n",
    "        (a, b, c) = extract_relationship(str(sent[1]))\n",
    "\n",
    "        # Add nodes and edges to graph\n",
    "        if a and b:\n",
    "            nx_graph.add_node(a, size = 5)\n",
    "            nx_graph.add_node(b, size = 5)\n",
    "            nx_graph.add_edge(a, b, weight=1, title=print_five_words(c), arrows=\"to\")\n",
    "\n",
    "g = Network(notebook=True, cdn_resources='in_line')\n",
    "g.from_nx(nx_graph)\n",
    "g.show(\"example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nx_graph.edges(['boston']))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
